{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d948c101",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Resizing](#Resizing-function)\n",
    "2. [Preprocessing](#Preprocessing)\n",
    "3. [Shape-Based Detection](#Shape-based-segmentation)\n",
    "4. [Color-Based Detection](#Color-based-segmentation)\n",
    "5. [Evaluation Functions](#Evaluation-functions)\n",
    "6. [Main Function](#Main-function)\n",
    "7. [Final Evaluation](#Final-evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b913ed-93d6-471f-930b-ecda01c026f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import sys\n",
    "import cv2 as cv\n",
    "from urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da585f5d-d1a5-4fe8-be77-3387df76d453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup\n",
    "assert sys.version_info >= (3, 8)\n",
    "\n",
    "if not cv.useOptimized():\n",
    "    cv.setUseOptimized(True)\n",
    "\n",
    "cv.useOptimized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1073a72-3ea1-491f-a12e-cee43a59db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to display images\n",
    "def display_image(window_name, image):\n",
    "    \"\"\" Display one image\n",
    "    Arguments:\n",
    "    ---\n",
    "    window_name: str\n",
    "    image: NumPy array\n",
    "    adjust: fit the image to monitor size (boolean)\n",
    "    \n",
    "    Return:\n",
    "    ---\n",
    "    A window showing an image\"\"\"\n",
    "    # if adjust:\n",
    "    #     cv.namedWindow(window_name, cv.WINDOW_NORMAL)\n",
    "    # else:\n",
    "    #     cv.namedWindow(window_name)\n",
    "    cv.imshow(window_name, image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe351992-28e1-44ae-ab77-f239e82231ee",
   "metadata": {},
   "source": [
    "### Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d987ba5-ffcc-449d-aa05-507c8fb6b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, target_width=224):\n",
    "    \"\"\"\n",
    "    Resizes the image to the target width while maintaining the aspect ratio.\n",
    "\n",
    "    Args:\n",
    "        img: The input image.\n",
    "        target_width: The desired width for the resized image.\n",
    "\n",
    "    Returns:\n",
    "        The resized image and the scale factor.\n",
    "    \"\"\"\n",
    "    # Get original dimensions\n",
    "    original_height, original_width = img.shape[:2]\n",
    "    \n",
    "    # Calculate the scaling factor\n",
    "    scale_factor = target_width / original_width\n",
    "    \n",
    "    # Calculate the new dimensions\n",
    "    new_width = target_width\n",
    "    new_height = int(original_height * scale_factor)\n",
    "    \n",
    "    # Resize the image\n",
    "    img_resized = cv.resize(img, (new_width, new_height))\n",
    "    \n",
    "    return img_resized, scale_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b5586-33c9-4eaa-9696-72f16d902e79",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "224e0122-c171-41c5-9027-483701672a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_shape_based(image):\n",
    "    \"\"\"\n",
    "    Converts the input image to grayscale and applies Gaussian blur for preprocessing.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The input BGR image.\n",
    "\n",
    "    Returns:\n",
    "    - blurred: The preprocessed grayscale and blurred image.\n",
    "    \"\"\"\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    equalized = cv.equalizeHist(gray) # Apply histogram equalization\n",
    "    blurred = cv.GaussianBlur(gray, (5, 5), 0)  # Apply Gaussian blur\n",
    "\n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "addf9be6-14b7-4ed3-baf6-33b2b6dba6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_color_based(img):\n",
    "    \"\"\"\n",
    "    Preprocess an image by applying Gaussian blur and gamma correction.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    img : numpy.ndarray\n",
    "        The input image\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        The preprocessed image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    image_preprocessed = cv.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Apply Gamma Correction (adjusts the brightness and contrast)\n",
    "    gamma = 0.8\n",
    "    look_up_table = np.array([((i / 255.0) ** gamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    image_preprocessed = cv.LUT(image_preprocessed, look_up_table)\n",
    "    \n",
    "    return image_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16620f8-3ab4-4248-94ef-2d476b809e46",
   "metadata": {},
   "source": [
    "### Shape-based segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b4fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(image):\n",
    "    \"\"\"\n",
    "    Detects edges in the input image using the Canny edge detection algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The preprocessed grayscale image.\n",
    "\n",
    "    Returns:\n",
    "    - edges: The binary image showing detected edges.\n",
    "    \"\"\"\n",
    "    edges = cv.Canny(image, 50, 150)  # Apply Canny edge detection\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def find_contours(edges):\n",
    "    \"\"\"\n",
    "    Finds contours in the binary edge-detected image and returns an image with contours drawn.\n",
    "\n",
    "    Parameters:\n",
    "    - edges: The binary image resulting from edge detection.\n",
    "\n",
    "    Returns:\n",
    "    - contours_image: An image with contours drawn.\n",
    "    - contours: A list of found contours.\n",
    "    \"\"\"\n",
    "    # Find contours\n",
    "    contours, _ = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a blank image to draw contours\n",
    "    contours_image = np.zeros_like(edges)  # Use the same size as the edges image\n",
    "\n",
    "    # Draw all contours on the blank image\n",
    "    cv.drawContours(contours_image, contours, -1, (255, 255, 255), 1)\n",
    "    \n",
    "    return contours_image, contours\n",
    "\n",
    "def classify_shape(contour):\n",
    "    \"\"\"\n",
    "    Classifies the shape of a contour based on its perimeter and the number of vertices.\n",
    "\n",
    "    Parameters:\n",
    "    - contour: A contour from the list of detected contours.\n",
    "\n",
    "    Returns:\n",
    "    - A string representing the identified shape ('Triangle', 'Square', 'Rectangle', 'Octagon', 'Circle', or 'Unknown').\n",
    "    \"\"\"\n",
    "    perimeter = cv.arcLength(contour, True)  # Calculate the perimeter of the contour\n",
    "\n",
    "    if perimeter == 0:  # To avoid division by zero in calculations\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    approx = cv.approxPolyDP(contour, 0.043 * perimeter, True)  \n",
    "    # Approximate the contour shape to reduce the number of points\n",
    "\n",
    "    if len(approx) == 3:\n",
    "        return \"Triangle\"\n",
    "    elif len(approx) == 4:\n",
    "        x, y, w, h = cv.boundingRect(approx)  # Get the bounding box of the approximated contour\n",
    "        aspect_ratio = float(w) / h  # Calculate the aspect ratio of the bounding box\n",
    "        if 0.95 <= aspect_ratio <= 1.05:\n",
    "            return \"Square\"\n",
    "        else:\n",
    "            return \"Rectangle\"\n",
    "    elif len(approx) == 8:\n",
    "        return \"Octagon\"\n",
    "    else:\n",
    "        area = cv.contourArea(contour)  # Calculate the area of the contour\n",
    "        circularity = 4 * np.pi * (area / (perimeter * perimeter))  # Compute the circularity\n",
    "        if 0.8 < circularity < 1.2:\n",
    "            return \"Circle\"\n",
    "    \n",
    "    return \"Unknown\"\n",
    "\n",
    "def filter_sign_contours(contours):\n",
    "    \"\"\"\n",
    "    Filters contours to retain only those representing specific shapes.\n",
    "\n",
    "    Parameters:\n",
    "    - contours: A list of contours.\n",
    "\n",
    "    Returns:\n",
    "    - sign_contours: A list of contours with their shapes if they are among the specific shapes.\n",
    "    \"\"\"\n",
    "    sign_contours = []\n",
    "    for contour in contours:\n",
    "        shape = classify_shape(contour)\n",
    "        if shape in [\"Triangle\", \"Square\", \"Rectangle\", \"Circle\", \"Octagon\"]:\n",
    "            sign_contours.append((contour, shape))\n",
    "    return sign_contours\n",
    "\n",
    "def get_largest_contour(contours):\n",
    "    \"\"\"\n",
    "    Identifies the largest contour by area from a list of contours.\n",
    "\n",
    "    Parameters:\n",
    "    - contours: A list of contours.\n",
    "\n",
    "    Returns:\n",
    "    - largest_contour: The largest contour found (if any).\n",
    "    - shape: The shape of the largest contour identified.\n",
    "    \"\"\"\n",
    "    if not contours:\n",
    "        return None, None\n",
    "    return max(contours, key=lambda x: cv.contourArea(x[0]))\n",
    "\n",
    "def segment_sign(image, contour):\n",
    "    \"\"\"\n",
    "    Segments the area of the image corresponding to the detected contour.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The original input image.\n",
    "    - contour: The contour that outlines the area to be segmented.\n",
    "\n",
    "    Returns:\n",
    "    - segmented: The segmented portion of the image corresponding to the contour.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)  # Create a black mask with the size of the image\n",
    "    cv.drawContours(mask, [contour], -1, 255, -1)  # Draw the contour on the mask in white\n",
    "    segmented = cv.bitwise_and(image, image, mask=mask)  # Apply the mask to the image\n",
    "    return segmented\n",
    "\n",
    "def shape_process_image(image):\n",
    "    \"\"\"\n",
    "    Processes the input image to detect and segment the largest contour, if any.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The input image in BGR format.\n",
    "\n",
    "    Returns:\n",
    "    - edges: The binary image of detected edges.\n",
    "    - contours_image: The image with contours drawn.\n",
    "    - largest_contour: The largest contour detected (if any).\n",
    "    - shape: The shape of the largest contour (if any).\n",
    "    - segmented_sign: The segmented part of the image corresponding to the largest contour.\n",
    "    \"\"\"\n",
    "    preprocessed_image = preprocess_image_for_shape_based(image)  # Preprocess the image\n",
    "    edges = detect_edges(preprocessed_image)  # Detect edges in the preprocessed image\n",
    "    contours_image, contours = find_contours(edges)  # Find contours from the edge-detected image\n",
    "    sign_contours, sign_shapes = filter_sign_contours(contours)  # Filter relevant contours\n",
    "    largest_contour, shape = get_largest_contour(sign_contours, sign_shapes)  # Identify the largest relevant contour\n",
    "    \n",
    "    if largest_contour is not None:\n",
    "        segmented_sign = segment_sign(image, largest_contour)  # Segment the largest contour from the image\n",
    "        return preprocessed_image, edges, contours_image, largest_contour, shape, segmented_sign  # Return results\n",
    "    else:\n",
    "        return preprocessed_image, edges, contours_image, None, None, None  # Return if no contour is found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a8fff-6a77-4850-84e2-21abc704ccb0",
   "metadata": {},
   "source": [
    "### Color-based segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decdc229-3e6c-40df-8319-2013cfdd79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(image):\n",
    "    \"\"\"\n",
    "    Create a mask for yellow, blue, and red colors in an image and apply it to the original image.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): Input image in BGR\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Segmented image with only yellow, blue, and red colors visible.\n",
    "                   All other colors are masked out (black).\n",
    "    \"\"\"\n",
    "\n",
    "    hsv = cv.cvtColor(image, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define color ranges for yellow, blue, and red in HSV\n",
    "    yellow_lower = np.array([19, 100, 100])\n",
    "    yellow_upper = np.array([37, 255, 255])\n",
    "\n",
    "    blue_lower = np.array([90, 100, 100])\n",
    "    blue_upper = np.array([115, 255, 255])\n",
    "\n",
    "    # Red wraps around the hue spectrum, so we need two ranges\n",
    "    red_lower1 = np.array([0, 100, 100])\n",
    "    red_upper1 = np.array([10, 255, 255])\n",
    "    red_lower2 = np.array([160, 100, 100])\n",
    "    red_upper2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Create masks for each color\n",
    "    yellow_mask = cv.inRange(hsv, yellow_lower, yellow_upper)\n",
    "    blue_mask = cv.inRange(hsv, blue_lower, blue_upper)\n",
    "    red_mask1 = cv.inRange(hsv, red_lower1, red_upper1)\n",
    "    red_mask2 = cv.inRange(hsv, red_lower2, red_upper2)\n",
    "    red_mask = cv.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "    # Combine masks\n",
    "    combined_mask = cv.bitwise_or(yellow_mask, blue_mask)\n",
    "    combined_mask = cv.bitwise_or(combined_mask, red_mask)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv.bitwise_and(image, image, mask=combined_mask)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c583c7-50da-4653-808f-141f3dc4479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_thresh(masked_image):\n",
    "    \"\"\"\n",
    "    Apply Otsu's thresholding to the v channel of image.\n",
    "\n",
    "    This function takes an image in BGR format, converts it to the HSV color space,\n",
    "    and extracts the value (V) channel. Otsu's thresholding is then applied to this\n",
    "    channel to create a binary thresholded image. The resulting binary image is\n",
    "    converted back to a 3-channel BGR format and returned.\n",
    "\n",
    "    Parameters:\n",
    "    masked_image (numpy.ndarray): The input image in BGR format.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The thresholded image in BGR format.\n",
    "    \"\"\"\n",
    "    # extract the value channel\n",
    "    v_channel = cv.split(cv.cvtColor(masked_image, cv.COLOR_BGR2HSV))[2]\n",
    "\n",
    "    # Apply otsu thresholding\n",
    "    _, thresh = cv.threshold(v_channel, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "\n",
    "    # Convert output 2D image to 3D\n",
    "    thresh = cv.cvtColor(thresh, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff57381-68d2-4015-b73d-0bbf501314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphological_expansion(image, kernel_size=5, iterations=1):\n",
    "    \"\"\"\n",
    "    Perform morphological expansion (dilation) on an image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : numpy.ndarray\n",
    "        The input image on which to apply morphological expansion.\n",
    "    kernel_size : int, optional\n",
    "        The size of the square structuring element (kernel) used for dilation. \n",
    "        Defaults to 5.\n",
    "    iterations : int, optional\n",
    "        The number of times the dilation operation is applied. \n",
    "        Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        The image after morphological expansion, where the objects in the image \n",
    "        are expanded based on the kernel size and number of iterations.\n",
    "    \"\"\"\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (kernel_size, kernel_size))\n",
    "\n",
    "    expanded_image = cv.morphologyEx(image, cv.MORPH_DILATE, kernel, iterations=iterations)\n",
    "\n",
    "    return expanded_image\n",
    "\n",
    "def morphological_erosion(image, kernel_size=5, iterations=1):\n",
    "    \"\"\"\n",
    "    Perform morphological erosion on an image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : numpy.ndarray\n",
    "        The input image on which to apply morphological erosion.\n",
    "    kernel_size : int, optional\n",
    "        The size of the square structuring element (kernel) used for erosion. \n",
    "        Defaults to 5.\n",
    "    iterations : int, optional\n",
    "        The number of times the erosion operation is applied. \n",
    "        Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        The image after morphological erosion, where the objects in the image \n",
    "        are eroded based on the kernel size and number of iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_RECT, (kernel_size, kernel_size))\n",
    "\n",
    "    eroded_image = cv.morphologyEx(image, cv.MORPH_ERODE, kernel, iterations=iterations)\n",
    "\n",
    "    return eroded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896b952d-f04e-4a58-9533-7353347ce40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour(src_image):\n",
    "    \"\"\"\n",
    "    Extract contours from an image and identify the longest contour.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    src_image : numpy.ndarray\n",
    "        The input image from which to extract contours. The image should be in BGR format.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        - contours (list of numpy.ndarray): A list of contours found in the image. Each contour is an array of points.\n",
    "        - longest_contour (numpy.ndarray): The contour with the maximum area based on the contour's area. If no contours are found, returns None.\n",
    "    \"\"\"\n",
    "    if len(src_image.shape) != 2:\n",
    "        image_gray = cv.cvtColor(src_image, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "    else:\n",
    "        image_gray = src_image\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours = []\n",
    "    contours, _ = cv.findContours(image_gray, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return src_image, None\n",
    "    # Find the longest contour based on arc length (perimeter)\n",
    "    longest_contour = max(contours, key=cv.contourArea)\n",
    "\n",
    "    return contours, longest_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78f52e62-25e8-463b-9be5-e42c9ac6ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(src, contours, longest=True):\n",
    "    \"\"\"\n",
    "    Draw contours on a copy of the source image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    src : numpy.ndarray\n",
    "        The source image on which contours will be drawn.\n",
    "    contours : list of numpy.ndarray\n",
    "        A list of contours, where each contour is an array of points.\n",
    "    longest : bool, optional\n",
    "        If True, only the contour with the maximum area is drawn. If False, all contours in the list are drawn. Default=True.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        A copy of the source image with the specified contours drawn. If `longest` is True, only the contour with the maximum area is drawn\n",
    "    \"\"\"\n",
    "    \n",
    "    img_copy = src.copy()\n",
    "\n",
    "    if longest:\n",
    "        # Draw max contour\n",
    "        longest_contour = max(contours, key=cv.contourArea)\n",
    "        cv.drawContours(img_copy, [longest_contour], -1, (0, 255, 0), 2)\n",
    "    else:\n",
    "        # draw all contours\n",
    "        cv.drawContours(img_copy, contours, -1, (0, 255, 0), 2)\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1826563-fb8b-44ef-9c09-bbc1a8714ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_longest_contour(src, longest_contour):\n",
    "    \"\"\"\n",
    "    Create a binary mask from the longest contour in an image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    src : numpy.ndarray\n",
    "        The input image used to define the mask's dimensions. It should be in BGR format.\n",
    "    longest_contour : numpy.ndarray\n",
    "        The contour used to create the mask. It is an array of points representing the longest contour.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        A binary mask\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a blank mask with the same dimensions as the input image\n",
    "    mask = np.zeros_like(src)\n",
    "\n",
    "    if longest_contour is not None:\n",
    "        # Fill the longest contour on the mask\n",
    "        cv.drawContours(mask, [longest_contour], -1, (255, 255, 255), thickness=cv.FILLED)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e14f54fc-8a06-4edf-99ff-8aaa746846ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(src, mask):\n",
    "    \"\"\"\n",
    "    Segment an image using a binary mask.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    src : numpy.ndarray\n",
    "        The source image to be segmented.\n",
    "    mask : numpy.ndarray\n",
    "        A binary mask where the regions to be kept are non-zero, and the regions to be discarded are zero.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    segmented image (numpy.ndarray)\n",
    "        \n",
    "    \"\"\"\n",
    "    img_copy = src.copy()\n",
    "    img_segmented = cv.bitwise_and(src, mask)\n",
    "    \n",
    "    return img_segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a9251-b1cc-4fce-889d-81e3d6623e9c",
   "metadata": {},
   "source": [
    "### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43f51fa0-8d02-4c23-af0a-b1e14efc511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground truth bounding box coordinate\n",
    "def ground_truth_bb(image_annot_dir, scale_factor, image_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ground truth bounding box coordinates from  annotation file\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_annot_dir : str\n",
    "        The directory path to the annotation file containing bounding box information.\n",
    "    scale_factor : float\n",
    "        The factor by which the images are resized\n",
    "    image_name : str\n",
    "        The name of the image file (including the extension) for which the bounding box coordinates are required.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        A tuple containing the scaled bounding box coordinates in the form (x1, y1, x2, y2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # check if the file directory exists\n",
    "    if not (os.path.exists(image_annot_dir)):\n",
    "        print(\"{} does not exist!\".format(image_annot_dir))\n",
    "        return None\n",
    "    \n",
    "    # read file\n",
    "    inFile = open(image_annot_dir, 'r')\n",
    "    found = False\n",
    "    for annot in inFile:\n",
    "        # example annot: image_1.png;103;90;19;12;88;78;0;\n",
    "        annot_splited = annot.split(\";\")\n",
    "        \n",
    "        image_file_name = annot_splited[0]\n",
    "        image_size = annot_splited[1:3]\n",
    "        image_bb = annot_splited[3:7]\n",
    "        image_class = annot_splited[7]\n",
    "\n",
    "        if (image_name == image_file_name):\n",
    "            new_coord = [int(coord) * scale_factor for coord in image_bb]\n",
    "            new_coord = tuple(map(round, new_coord)) # round floating point to integers\n",
    "            # print(image_name, new_coord)\n",
    "            found = True\n",
    "            return new_coord\n",
    "            \n",
    "    if not found:\n",
    "        print(\"{} does not exist\".format(image_name))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "814a680d-00c3-4093-bf95-edc093a4c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ground truth bounding box\n",
    "def plot_ground_truth(dst, coord):\n",
    "    \"\"\"\n",
    "    Plot the ground truth bounding box on an image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dst : numpy.ndarray\n",
    "        The input image on which the ground truth bounding box will be drawn.\n",
    "    coord : tuple\n",
    "        The coordinates of the ground truth bounding box in the form (x1, y1, x2, y2),\n",
    "        where (x1, y1) represent the top-left corner and (x2, y2) represent the bottom-right corner.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        The image with the ground truth bounding box and label drawn.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_copy = dst.copy()\n",
    "    x1, y1, x2, y2 = coord\n",
    "    cv.rectangle(img_copy, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    cv.putText(img_copy, 'ground truth', (x1, y1-10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv.LINE_AA)\n",
    "    \n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aff1e9fa-84d3-4d66-bd3e-c0a9f29e5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_and_pred_bounding_box(dst, c):\n",
    "    \"\"\"\n",
    "    Draw bounding box around a contour and add a prediction label to the image.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dst (numpy.ndarray): The destination image on which the bounding box will be drawn.\n",
    "    c (array-like): contour for which the bounding box will be computed.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        img_copy (numpy.ndarray): The image with the bounding box and label drawn.\n",
    "        coord (tuple): coordinates of the bounding box (top-left corner and bottom-right corner)\n",
    "    \"\"\"\n",
    "    \n",
    "    (x, y, w, h) = cv.boundingRect(c)\n",
    "    coord = (x, y, x + w, y + h)\n",
    "    img_copy = dst.copy()\n",
    "    cv.rectangle(img_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv.putText(img_copy, 'predicted', (x, y+h+20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv.LINE_AA)\n",
    "    \n",
    "    return img_copy, coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdb6feed-8487-46fc-a121-e775b860f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IOU(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union of two bounding boxes\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    boxA, boxB : tuple or list of four integers\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    IOU (float)\n",
    "    \"\"\"\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    \n",
    "    # compute intersection area\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    \n",
    "    # compute union area\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "\n",
    "    # compute IOU\n",
    "    iou = interArea / float(unionArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "026c12f0-3827-45f6-84dc-6754aaeb3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculate the Dice coefficient between two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    boxA, boxB : tuple\n",
    "        A tuple representing the coordinates of the bounding box in the format (x1, y1, x2, y2).\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The Dice coefficient, which measures the overlap between the two bounding boxes.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack coordinates\n",
    "    x1_A, y1_A, x2_A, y2_A = boxA\n",
    "    x1_B, y1_B, x2_B, y2_B = boxB\n",
    "    \n",
    "    # Calculate intersection\n",
    "    x1_inter = max(x1_A, x1_B)\n",
    "    y1_inter = max(y1_A, y1_B)\n",
    "    x2_inter = min(x2_A, x2_B)\n",
    "    y2_inter = min(y2_A, y2_B)\n",
    "    \n",
    "    # Check if there is an intersection\n",
    "    inter_width = max(0, x2_inter - x1_inter)\n",
    "    inter_height = max(0, y2_inter - y1_inter)\n",
    "    area_inter = inter_width * inter_height\n",
    "    \n",
    "    # Calculate areas of each box\n",
    "    area_A = (x2_A - x1_A) * (y2_A - y1_A)\n",
    "    area_B = (x2_B - x1_B) * (y2_B - y1_B)\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    dice = (2 * area_inter) / (area_A + area_B)\n",
    "    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7afdc98-e891-407f-b5b7-624eeb6b8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_caption(image, caption):\n",
    "    \"\"\"\n",
    "    Add caption below an image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The input image to which a caption will be added.\n",
    "    - caption: The text to be added as a caption.\n",
    "\n",
    "    Returns:\n",
    "    - caption_image: image with caption added below\n",
    "    \"\"\"\n",
    "    # Ensure the image is in BGR format\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv.cvtColor(image, cv.COLOR_GRAY2BGR)\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    # Create a new image with extra space for the caption\n",
    "    caption_image = np.zeros((h + 30, w, 3), dtype=np.uint8)\n",
    "    caption_image[:h, :w] = image  # Copy the input image to the new image\n",
    "\n",
    "    # Add text caption\n",
    "    cv.putText(caption_image, caption, (10, h + 20), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv.LINE_AA)\n",
    "\n",
    "    return caption_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457764b-4300-4e48-b992-2c431472d893",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21d53834-39f2-4765-9f4b-729fb156f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# directory of text file that stores ground truth bouding box coordinates\n",
    "image_annot_dir = \"image_coordinates.txt\"\n",
    "\n",
    "# list to store the performance\n",
    "image_list = []\n",
    "IOU_list = []\n",
    "DICE_list = []\n",
    "detection_time_list = []\n",
    "total_time_list = []\n",
    "\n",
    "# loop through image_1.png to image_101.png\n",
    "for i in range(1, 101):\n",
    "    image_name = f\"image_{i}.png\"\n",
    "    image_path = f'Samples of 100/Samples of 100/{image_name}'\n",
    "\n",
    "    # Read the image\n",
    "    img = cv.imread(image_path)\n",
    "\n",
    "    # check if image is loaded\n",
    "    if img is None:\n",
    "        print(f\"Image {image_path} not found.\")\n",
    "        continue\n",
    "    start_time = time.time()\n",
    "    img_resized, scale_factor = resize_image(img)\n",
    "\n",
    "    # ===============================================\n",
    "    # SHAPE\n",
    "    # ===============================================\n",
    "    \n",
    "    preprocessed_image_shape = preprocess_image_for_shape_based(img_resized)  # Preprocess the image\n",
    "    edges = detect_edges(preprocessed_image_shape)  # Detect edges in the preprocessed image\n",
    "    contours_image, contours = find_contours(edges)  # Find contours from the edge-detected image\n",
    "    sign_contours = filter_sign_contours(contours)  # Filter relevant contours\n",
    "    largest_contour, shape = get_largest_contour(sign_contours)  # Identify the largest relevant contour\n",
    "    \n",
    "    largest_contour_image = img_resized.copy()\n",
    "    \n",
    "    if largest_contour is not None:\n",
    "        cv.drawContours(largest_contour_image, [largest_contour], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    shape_mask = create_mask_from_longest_contour(img_resized, largest_contour)\n",
    "    shape_segmented_image = segment_image(img_resized, shape_mask)\n",
    "    \n",
    "    # ==================================================\n",
    "    # COLOR\n",
    "    # ==================================================\n",
    "\n",
    "    preprocessed_image_color = preprocess_image_for_color_based(img_resized) # preprocess the image\n",
    "    masked_image = mask_image(preprocessed_image_color) # create mask\n",
    "    thresh = otsu_thresh(masked_image) # perform otsu thresholding\n",
    "    \n",
    "    # Apply morphological operations\n",
    "    eroded_image = morphological_erosion(thresh, kernel_size=5)\n",
    "    expanded_image = morphological_expansion(eroded_image, kernel_size=3)\n",
    "\n",
    "    # find the longest contours and use it to segment the traffic sign \n",
    "    contours, longest_contour = get_contour(expanded_image)\n",
    "    contour_image = draw_contours(expanded_image, contours)\n",
    "    color_mask = create_mask_from_longest_contour(img_resized, longest_contour)\n",
    "    color_segmented_image = segment_image(img_resized, color_mask)\n",
    "    \n",
    "    # ===========================================================\n",
    "    # post-processing\n",
    "    # ===========================================================\n",
    "    \n",
    "    # perform bitwise or operation on shape mask and color mask\n",
    "    combined_mask = shape_mask | color_mask\n",
    "    \n",
    "    # retrive the largest contour\n",
    "    final_contours, final_contour = get_contour(combined_mask)\n",
    "\n",
    "    # create mask from longest contour\n",
    "    final_mask = create_mask_from_longest_contour(img_resized, final_contour)\n",
    "\n",
    "    # segment image\n",
    "    combined_segmented_image = segment_image(img_resized, final_mask)\n",
    "    \n",
    "    # End timing for detection and segmentation\n",
    "    end_detection_time = time.time()\n",
    "\n",
    "    # =======================================\n",
    "    # Evaluate performance\n",
    "    # =======================================\n",
    "    \n",
    "    # get coordinates of predicted bounding box\n",
    "    if(largest_contour is not None):\n",
    "        bounding_box_image, coord = draw_and_pred_bounding_box(img_resized, final_contour)\n",
    "    else:\n",
    "        bounding_box_image = img_resized.copy()\n",
    "    \n",
    "    # get coordinates of ground truth\n",
    "    ground_truth_coord = ground_truth_bb(image_annot_dir, scale_factor, image_name)\n",
    "    bounding_box_image = plot_ground_truth(bounding_box_image, ground_truth_coord)\n",
    "\n",
    "    # calculate performance metrics\n",
    "    IOU = calc_IOU(coord, ground_truth_coord)\n",
    "    DICE = calc_dice(coord, ground_truth_coord)\n",
    "    \n",
    "    end_total_time = time.time()\n",
    "    \n",
    "    # Calculate time\n",
    "    detection_time = end_detection_time - start_time\n",
    "    total_time = end_total_time - start_time\n",
    "\n",
    "    # store the performance in list\n",
    "    image_list.append(image_name)\n",
    "    IOU_list.append(IOU)\n",
    "    DICE_list.append(DICE)\n",
    "    detection_time_list.append(detection_time)\n",
    "    total_time_list.append(total_time)\n",
    "\n",
    "    # ==================================================\n",
    "    # formatting output display\n",
    "    # ==================================================\n",
    "\n",
    "    # placeholder to match shape for display\n",
    "    placeholder_image = np.ones_like(img_resized)\n",
    "\n",
    "    # Add captions\n",
    "    placeholder_image_with_caption        = add_caption(placeholder_image, \"Placeholder\")\n",
    "    image_with_caption                    = add_caption(img_resized, \"Original\")\n",
    "    # ============================================================\n",
    "    preprocessed_image_color_with_caption = add_caption(preprocessed_image_color, \"Preprocessed (Color)\")\n",
    "    masked_image_with_caption             = add_caption(masked_image, \"color mask\")\n",
    "    thresh_with_caption                   = add_caption(thresh, \"threshold\")\n",
    "    morphed_image_with_caption            = add_caption(expanded_image, \"morhped\")\n",
    "    contour_image_with_caption            = add_caption(contour_image, \"Longest contour (color)\")\n",
    "    color_segmented_image_with_caption    = add_caption(color_segmented_image, \"Color segmented\")\n",
    "    # ============================================================\n",
    "    preprocessed_image_shape_with_caption = add_caption(preprocessed_image_shape, \"Preprocessed (Shape)\")\n",
    "    edges_image_with_caption              = add_caption(edges, \"Edge Detection\")\n",
    "    contours_image_with_caption           = add_caption(contours_image, \"All Contours\")\n",
    "    largest_contour_image_with_caption    = add_caption(largest_contour_image, \"Longest Contour (shape)\")\n",
    "    shape_segmented_image_with_caption    = add_caption(shape_segmented_image, \"Shape segmented\")\n",
    "    # ===========================================================\n",
    "    combined_segmented_image_with_caption = add_caption(combined_segmented_image, \"Final Segmented Sign\")\n",
    "    bounding_box_image_with_caption       = add_caption(bounding_box_image, \"Bounding Box\")\n",
    "\n",
    "    # =================================================\n",
    "    # create ouput window for display\n",
    "    # ================================================\n",
    "\n",
    "    # combined color and shape\n",
    "    result = np.hstack((image_with_caption,\n",
    "                        color_segmented_image_with_caption,\n",
    "                        shape_segmented_image_with_caption, \n",
    "                        combined_segmented_image_with_caption,\n",
    "                        bounding_box_image_with_caption\n",
    "                       ))\n",
    "    \n",
    "    # color\n",
    "    color_row_1 = np.hstack((image_with_caption,\n",
    "                             preprocessed_image_color_with_caption,\n",
    "                             masked_image_with_caption, \n",
    "                             thresh_with_caption\n",
    "                            ))\n",
    "    \n",
    "    color_row_2 = np.hstack((morphed_image_with_caption,\n",
    "                             contour_image_with_caption,\n",
    "                             color_segmented_image_with_caption,\n",
    "                             placeholder_image_with_caption\n",
    "                            ))\n",
    "\n",
    "    color_result = np.vstack((color_row_1, color_row_2))\n",
    "\n",
    "    # shape\n",
    "    shape_row_1 = np.hstack((image_with_caption,\n",
    "                             preprocessed_image_shape_with_caption,\n",
    "                             edges_image_with_caption,\n",
    "                            ))\n",
    "    \n",
    "    shape_row_2 = np.hstack((contours_image_with_caption,\n",
    "                             largest_contour_image_with_caption,\n",
    "                             shape_segmented_image_with_caption\n",
    "                            ))\n",
    "\n",
    "    shape_result = np.vstack((shape_row_1, shape_row_2))\n",
    "    \n",
    "    # ==================================================\n",
    "    #            Display final results\n",
    "    # ==================================================\n",
    "    # modifiy to display the desired outputs\n",
    "    \n",
    "    display_image(\"image_{}\".format(i), result) # display results for color and shape combined\n",
    "    \n",
    "    # display_image(\"image_{}\".format(i), color_result) # display color pipeline in details\n",
    "\n",
    "    # display_image(\"image_{}\".format(i), shape_result) # display shape pipeline in details\n",
    "\n",
    "    # ===================================================\n",
    "    # Save all results on local machine\n",
    "    # ===================================================\n",
    "    # Saving the processed images for combined, shape-only, and color-only results into their respective directories.\n",
    "    # The image is saved in three different locations:\n",
    "    # - combined_results_path: Stores the image with both color and shape analysis results.\n",
    "    # - shape_results_path: Stores the image with only shape analysis results.\n",
    "    # - color_results_path: Stores the image with only color analysis results.\n",
    "\n",
    "    # Define the output directories\n",
    "    combined_results_dir = 'Color and Shape Results'\n",
    "    color_results_dir = 'Color Results'\n",
    "    shape_results_dir = 'Shape Results'\n",
    "\n",
    "    # create output directories\n",
    "    os.makedirs(combined_results_dir, exist_ok=True)\n",
    "    os.makedirs(color_results_dir, exist_ok=True)\n",
    "    os.makedirs(shape_results_dir, exist_ok=True)\n",
    "\n",
    "    # save results\n",
    "    combined_results_path = os.path.join(combined_results_dir, f'image_{i}.png')\n",
    "    cv.imwrite(combined_results_path, result)\n",
    "    \n",
    "    shape_results_path = os.path.join(shape_results_dir, f'image_{i}.png')\n",
    "    cv.imwrite(shape_results_path, shape_result)\n",
    "\n",
    "    color_results_path = os.path.join(color_results_dir, f'image_{i}.png')\n",
    "    cv.imwrite(color_results_path, color_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fce62-90b0-4bf5-9fc4-ff95bb75485b",
   "metadata": {},
   "source": [
    "### Final evaluation\n",
    "To evaluate the performance of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49a0abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from the lists\n",
    "performance_metrics = {\n",
    "    \"img_name\": image_list,\n",
    "    \"IOU\"     : IOU_list,\n",
    "    \"DICE\"    : DICE_list,\n",
    "    \"Detection and Segmentation Time\": detection_time_list,\n",
    "    \"Total Time\" : total_time_list\n",
    "}\n",
    "\n",
    "# Convert the dictionary to DataFrame\n",
    "df = pd.DataFrame(performance_metrics)\n",
    "\n",
    "# Display the DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7aff4cb-a8a0-400f-af02-c7259631a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average IOU and average DICE coefficient\n",
    "avg_IOU = df['IOU'].mean()\n",
    "avg_DICE = df['DICE'].mean()\n",
    "avg_detect = df['Detection and Segmentation Time'].mean()\n",
    "avg_total= df['Total Time'].mean()\n",
    "\n",
    "# Count the number of images that passed the IOU threshold of 0.5\n",
    "IOU_passed = [IOU for IOU in IOU_list if IOU > 0.5]\n",
    "num_passed = len(IOU_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83eb7ee1-e657-4f4d-81a1-8defa26fccfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average IOU = 0.9126\n",
      "average DICE = 0.952\n",
      "average detection and segmentation time = 0.0031\n",
      "average total time = 0.0035\n",
      "number of images passed = 100/100\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics\n",
    "print(\"average IOU =\", round(avg_IOU, 4))\n",
    "print(\"average DICE =\", round(avg_DICE, 4))\n",
    "print(\"average detection and segmentation time =\", round(avg_detect, 4))\n",
    "print(\"average total time =\", round(avg_total, 4))\n",
    "print(\"number of images passed = {}/{}\".format(num_passed, len(df['IOU'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa15f08e-a999-419e-853c-2a6643593f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images have failed the 0.5 IOU threshold.\n"
     ]
    }
   ],
   "source": [
    "# Find the indices where IOU is less than or equal to 0.5\n",
    "failed_indices = df[df['IOU'] <= 0.5].index.tolist()\n",
    "\n",
    "# Retrieve the corresponding image names using these indices\n",
    "failed_img_names = df.loc[failed_indices, 'img_name'].tolist()\n",
    "\n",
    "# Check if images have passed 0.5 IOU\n",
    "if not failed_img_names:\n",
    "    print(\"No images have failed the 0.5 IOU threshold.\")\n",
    "else:\n",
    "    print(f\"Images that failed the 0.5 IOU threshold: {failed_img_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "470859d4-7b86-4928-883b-197b58e5ec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the histogram of IOU\n",
    "plt.hist(df['IOU'], bins=np.linspace(0, 1, 11), edgecolor='black')\n",
    "plt.title('Histogram of IOU values')\n",
    "plt.xlabel('IOU')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Get the values and bin edges\n",
    "counts, bin_edges = np.histogram(df['IOU'], bins=np.linspace(0, 1, 11))\n",
    "\n",
    "# Annotate each bar with the number of instances, if count is not zero\n",
    "for count, x in zip(counts, bin_edges[:-1]):\n",
    "    if count > 0:\n",
    "        plt.text(x + (bin_edges[1] - bin_edges[0]) / 2, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a12c3b50-3a8a-4e22-9bad-e782873da8d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         img_name       IOU      DICE  Detection and Segmentation Time  \\\n",
      "0     image_1.png  0.798035  0.886969                         0.043054   \n",
      "1     image_2.png  0.810100  0.894351                         0.003502   \n",
      "2     image_3.png  0.850572  0.918656                         0.003137   \n",
      "3     image_4.png  0.907920  0.951403                         0.003245   \n",
      "4     image_5.png  0.833462  0.908552                         0.002911   \n",
      "5     image_6.png  0.967892  0.983577                         0.002102   \n",
      "6     image_7.png  0.947020  0.972603                         0.002273   \n",
      "7     image_8.png  0.899822  0.946920                         0.003113   \n",
      "8     image_9.png  0.831925  0.907600                         0.002949   \n",
      "9    image_10.png  0.870147  0.930125                         0.003093   \n",
      "10   image_11.png  0.916667  0.956268                         0.002006   \n",
      "11   image_12.png  0.929293  0.963104                         0.001977   \n",
      "12   image_13.png  0.882821  0.937373                         0.002493   \n",
      "13   image_14.png  0.921243  0.958766                         0.001999   \n",
      "14   image_15.png  0.939842  0.968746                         0.001983   \n",
      "15   image_16.png  0.987651  0.993748                         0.002998   \n",
      "16   image_17.png  0.938949  0.968332                         0.003006   \n",
      "17   image_18.png  0.973122  0.986303                         0.002242   \n",
      "18   image_19.png  0.967742  0.983498                         0.002788   \n",
      "19   image_20.png  0.937463  0.967510                         0.003000   \n",
      "20   image_21.png  0.967013  0.983116                         0.003015   \n",
      "21   image_22.png  0.861689  0.925178                         0.001999   \n",
      "22   image_23.png  0.967742  0.983498                         0.001982   \n",
      "23   image_24.png  0.873794  0.932133                         0.002096   \n",
      "24   image_25.png  0.916799  0.956323                         0.002032   \n",
      "25   image_26.png  0.857555  0.922878                         0.003293   \n",
      "26   image_27.png  0.977076  0.988337                         0.002958   \n",
      "27   image_28.png  0.988889  0.994382                         0.002613   \n",
      "28   image_29.png  0.927779  0.962301                         0.002995   \n",
      "29   image_30.png  0.949081  0.973738                         0.002513   \n",
      "30   image_31.png  0.951682  0.975067                         0.003041   \n",
      "31   image_32.png  0.955621  0.977159                         0.002292   \n",
      "32   image_33.png  0.610143  0.756339                         0.004096   \n",
      "33   image_34.png  0.894235  0.943851                         0.002326   \n",
      "34   image_35.png  0.955613  0.977155                         0.003014   \n",
      "35   image_36.png  0.944657  0.971378                         0.000997   \n",
      "36   image_37.png  0.892607  0.942916                         0.002099   \n",
      "37   image_38.png  0.884993  0.938520                         0.003013   \n",
      "38   image_39.png  0.931242  0.964165                         0.002045   \n",
      "39   image_40.png  0.932422  0.964806                         0.002206   \n",
      "40   image_41.png  0.928802  0.962837                         0.002518   \n",
      "41   image_42.png  0.959993  0.979448                         0.003427   \n",
      "42   image_43.png  0.814397  0.897121                         0.002613   \n",
      "43   image_44.png  0.977337  0.988473                         0.002000   \n",
      "44   image_45.png  0.977517  0.988566                         0.002532   \n",
      "45   image_46.png  0.722172  0.837372                         0.003111   \n",
      "46   image_47.png  0.928380  0.962608                         0.002688   \n",
      "47   image_48.png  0.889583  0.941134                         0.003038   \n",
      "48   image_49.png  0.928000  0.962343                         0.003682   \n",
      "49   image_50.png  0.943365  0.970643                         0.002872   \n",
      "50   image_51.png  0.977745  0.988684                         0.002001   \n",
      "51   image_52.png  0.917474  0.956695                         0.001002   \n",
      "52   image_53.png  0.927853  0.962293                         0.003369   \n",
      "53   image_54.png  0.912745  0.954083                         0.001959   \n",
      "54   image_55.png  0.896919  0.945328                         0.003007   \n",
      "55   image_56.png  0.934228  0.965763                         0.002510   \n",
      "56   image_57.png  0.925494  0.961004                         0.003131   \n",
      "57   image_58.png  0.955392  0.977013                         0.002999   \n",
      "58   image_59.png  0.926601  0.961637                         0.002993   \n",
      "59   image_60.png  0.931347  0.964222                         0.003604   \n",
      "60   image_61.png  0.971264  0.985337                         0.002103   \n",
      "61   image_62.png  0.946565  0.972332                         0.003602   \n",
      "62   image_63.png  0.944740  0.971382                         0.003542   \n",
      "63   image_64.png  0.918678  0.957314                         0.002993   \n",
      "64   image_65.png  0.965639  0.982417                         0.003006   \n",
      "65   image_66.png  0.978723  0.989170                         0.002093   \n",
      "66   image_67.png  0.955696  0.977199                         0.003081   \n",
      "67   image_68.png  0.945736  0.971888                         0.002006   \n",
      "68   image_69.png  0.949389  0.973867                         0.002602   \n",
      "69   image_70.png  0.822528  0.902004                         0.004516   \n",
      "70   image_71.png  0.523460  0.684234                         0.002053   \n",
      "71   image_72.png  0.992908  0.996416                         0.002000   \n",
      "72   image_73.png  0.985915  0.992857                         0.003089   \n",
      "73   image_74.png  0.986395  0.993103                         0.002007   \n",
      "74   image_75.png  0.956522  0.977611                         0.003021   \n",
      "75   image_76.png  0.973043  0.986243                         0.003104   \n",
      "76   image_77.png  0.942206  0.970020                         0.001999   \n",
      "77   image_78.png  0.942206  0.970020                         0.002089   \n",
      "78   image_79.png  0.733064  0.844985                         0.002002   \n",
      "79   image_80.png  0.965035  0.982079                         0.002006   \n",
      "80   image_81.png  0.939842  0.968746                         0.002300   \n",
      "81   image_82.png  0.965459  0.982301                         0.002482   \n",
      "82   image_83.png  0.633519  0.774001                         0.002099   \n",
      "83   image_84.png  0.893835  0.943520                         0.002007   \n",
      "84   image_85.png  0.970960  0.985157                         0.002998   \n",
      "85   image_86.png  0.970960  0.985157                         0.003547   \n",
      "86   image_87.png  0.937302  0.967334                         0.004091   \n",
      "87   image_88.png  0.838864  0.911778                         0.002000   \n",
      "88   image_89.png  0.857610  0.922756                         0.003006   \n",
      "89   image_90.png  0.838864  0.911778                         0.003000   \n",
      "90   image_91.png  0.964698  0.981924                         0.003006   \n",
      "91   image_92.png  0.962067  0.980516                         0.002388   \n",
      "92   image_93.png  0.986252  0.993030                         0.003098   \n",
      "93   image_94.png  0.915382  0.955541                         0.003530   \n",
      "94   image_95.png  0.898707  0.946270                         0.003086   \n",
      "95   image_96.png  0.915030  0.955325                         0.002997   \n",
      "96   image_97.png  0.880799  0.936116                         0.002006   \n",
      "97   image_98.png  0.970478  0.984905                         0.002001   \n",
      "98   image_99.png  0.872975  0.931666                         0.002005   \n",
      "99  image_100.png  0.915030  0.955325                         0.003090   \n",
      "\n",
      "    Total Time  \n",
      "0     0.045070  \n",
      "1     0.004511  \n",
      "2     0.004217  \n",
      "3     0.003507  \n",
      "4     0.003906  \n",
      "5     0.002102  \n",
      "6     0.002273  \n",
      "7     0.004100  \n",
      "8     0.002949  \n",
      "9     0.003093  \n",
      "10    0.003007  \n",
      "11    0.001977  \n",
      "12    0.002493  \n",
      "13    0.001999  \n",
      "14    0.003100  \n",
      "15    0.002998  \n",
      "16    0.003006  \n",
      "17    0.002242  \n",
      "18    0.003638  \n",
      "19    0.003000  \n",
      "20    0.003015  \n",
      "21    0.003102  \n",
      "22    0.002983  \n",
      "23    0.002096  \n",
      "24    0.002032  \n",
      "25    0.003593  \n",
      "26    0.003954  \n",
      "27    0.002613  \n",
      "28    0.002995  \n",
      "29    0.003520  \n",
      "30    0.003041  \n",
      "31    0.003387  \n",
      "32    0.004096  \n",
      "33    0.003482  \n",
      "34    0.003014  \n",
      "35    0.002470  \n",
      "36    0.002689  \n",
      "37    0.003013  \n",
      "38    0.003099  \n",
      "39    0.003118  \n",
      "40    0.003526  \n",
      "41    0.003427  \n",
      "42    0.002613  \n",
      "43    0.003077  \n",
      "44    0.002532  \n",
      "45    0.003111  \n",
      "46    0.002688  \n",
      "47    0.003038  \n",
      "48    0.003682  \n",
      "49    0.003951  \n",
      "50    0.002001  \n",
      "51    0.002081  \n",
      "52    0.003369  \n",
      "53    0.001959  \n",
      "54    0.004007  \n",
      "55    0.002510  \n",
      "56    0.003131  \n",
      "57    0.004001  \n",
      "58    0.002993  \n",
      "59    0.003604  \n",
      "60    0.003821  \n",
      "61    0.003602  \n",
      "62    0.004605  \n",
      "63    0.004611  \n",
      "64    0.003006  \n",
      "65    0.003680  \n",
      "66    0.003081  \n",
      "67    0.003006  \n",
      "68    0.002602  \n",
      "69    0.004516  \n",
      "70    0.002053  \n",
      "71    0.003000  \n",
      "72    0.003089  \n",
      "73    0.003096  \n",
      "74    0.003021  \n",
      "75    0.003104  \n",
      "76    0.002505  \n",
      "77    0.002089  \n",
      "78    0.003113  \n",
      "79    0.002006  \n",
      "80    0.003383  \n",
      "81    0.002482  \n",
      "82    0.002099  \n",
      "83    0.002007  \n",
      "84    0.003999  \n",
      "85    0.003547  \n",
      "86    0.004091  \n",
      "87    0.002000  \n",
      "88    0.004006  \n",
      "89    0.003000  \n",
      "90    0.003006  \n",
      "91    0.002388  \n",
      "92    0.004007  \n",
      "93    0.003530  \n",
      "94    0.003086  \n",
      "95    0.004158  \n",
      "96    0.003032  \n",
      "97    0.002001  \n",
      "98    0.003005  \n",
      "99    0.003090  \n"
     ]
    }
   ],
   "source": [
    "# display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d4de2b2-857a-4d36-be79-3ee10e4f8eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IOU</th>\n",
       "      <th>DICE</th>\n",
       "      <th>Detection and Segmentation Time</th>\n",
       "      <th>Total Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.912560</td>\n",
       "      <td>0.951985</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.078460</td>\n",
       "      <td>0.048837</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.004253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.523460</td>\n",
       "      <td>0.684234</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.001959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.893528</td>\n",
       "      <td>0.943369</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.002610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.931885</td>\n",
       "      <td>0.964514</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.962725</td>\n",
       "      <td>0.980868</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.003558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.996416</td>\n",
       "      <td>0.043054</td>\n",
       "      <td>0.045070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              IOU        DICE  Detection and Segmentation Time  Total Time\n",
       "count  100.000000  100.000000                       100.000000  100.000000\n",
       "mean     0.912560    0.951985                         0.003072    0.003513\n",
       "std      0.078460    0.048837                         0.004087    0.004253\n",
       "min      0.523460    0.684234                         0.000997    0.001959\n",
       "25%      0.893528    0.943369                         0.002080    0.002610\n",
       "50%      0.931885    0.964514                         0.002830    0.003059\n",
       "75%      0.962725    0.980868                         0.003082    0.003558\n",
       "max      0.992908    0.996416                         0.043054    0.045070"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the statistics of segmentation results\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
